{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Query Transformations for Improved Retrieval in RAG Systems\n",
        "\n",
        "## Overview\n",
        "\n",
        "이 코드는 검색 증강 생성(RAG) 시스템에서 검색 프로세스를 향상시키기 위해 세 가지 쿼리 변환 기법을 구현합니다.:\n",
        "\n",
        "1. Query Rewriting(쿼리 재작성)\n",
        "2. Step-back Prompting(한 발짝 물러서서 질문하기)\n",
        "3. Sub-query Decomposition(서브쿼리 분해)\n",
        "\n",
        "각 기법은 원래 쿼리를 수정하거나 확장함으로써 검색된 정보의 관련성과 포괄성을 향상시키는 것을 목표로 합니다.\n",
        "\n",
        "## Motivation\n",
        "\n",
        "RAG 시스템은 특히 복잡하거나 모호한 쿼리를 처리할 때 가장 관련성이 높은 정보를 검색하는 데 어려움을 겪는 경우가 많습니다. 이러한 쿼리 변환 기술은 쿼리를 재구성하여 관련 문서와 더 잘 일치하거나 더 포괄적인 정보를 검색함으로써 이 문제를 해결합니다.\n",
        "\n",
        "## Key Components\n",
        "\n",
        "1. Query Rewriting(쿼리 재작성): 보다 구체적이고 상세한 질문으로 재구성합니다.\n",
        "2. Step-back Prompting(한 발짝 물러서서 질문하기) : 더 나은 문맥 검색을 위해 더 광범위한 쿼리를 생성합니다.\n",
        "3. Sub-query Decomposition(서브쿼리 분해): 복잡한 쿼리를 더 간단한 하위 쿼리로 분해합니다.\n",
        "\n",
        "## 세부 방법\n",
        "\n",
        "### 1. Query Rewriting\n",
        "\n",
        "- **목적**: 검색어를 더욱 구체적이고 상세하게 만들어 관련 정보를 찾을 가능성을 높입니다.\n",
        "- **구현**:\n",
        "  - 사용자 지정 프롬프트 템플릿을 사용하는 GPT-4 모델을 사용합니다.\n",
        "  - 원래 질문을 가져와 더 구체적이고 상세하게 재구성합니다.\n",
        "\n",
        "### 2. Step-back Prompting\n",
        "\n",
        "- **목적**: 관련 배경 정보를 검색하는 데 도움이 될 수 있는 더 광범위하고 일반적인 쿼리를 생성하기 위해서입니다.\n",
        "- **구현**:\n",
        "  - 사용자 지정 프롬프트 템플릿을 사용하는 GPT-4 모델을 사용합니다.\n",
        "  - 원래 쿼리를 가져와서 보다 일반적인 '단계별' 쿼리를 생성합니다.\n",
        "\n",
        "### 3. Sub-query Decomposition\n",
        "\n",
        "- **목적**: 보다 포괄적인 정보 검색을 위해 복잡한 쿼리를 더 간단한 하위 쿼리로 분해합니다.\n",
        "- **구현**:\n",
        "  - 사용자 지정 프롬프트 템플릿을 사용하는 GPT-4 모델을 사용합니다.\n",
        "  - 원래 쿼리를 2~4개의 더 간단한 하위 쿼리로 분해합니다.\n",
        "\n",
        "## 이러한 접근 방식의 이점\n",
        "\n",
        "1. **관련성 향상**: 쿼리 재작성은 보다 구체적이고 관련성 높은 정보를 검색하는 데 도움이 됩니다.\n",
        "2. **더 나은 맥락**: Step-back prompting 방식은 더 넒은 맥락과 배경 정보를 떠올리는 데 도움이 됩니다.\n",
        "3. **종합적인 결과**: 서브쿼리 분해를 통해 복잡한 쿼리의 다양한 측면을 포괄하는 정보를 검색할 수 있습니다.\n",
        "4. **유연성**: 각 기술은 특정 사용 사례에 따라 독립적으로 또는 조합하여 사용할 수 있습니다.\n",
        "\n",
        "## 구현방법 상세\n",
        "\n",
        "- 모든 기술은 쿼리 변환을 위해 OpenAI의 GPT-4 모델을 사용합니다.\n",
        "- 사용자 지정 프롬프트 템플릿은 모델이 적절한 변환을 생성하도록 안내하는 데 사용됩니다.\n",
        "- 이 코드는 각 변환 기법에 대한 별도의 함수를 제공하므로 기존 RAG 시스템에 쉽게 통합할 수 있습니다.\n",
        "\n",
        "## 예시 사용 사례\n",
        "\n",
        "이 코드는 예제 쿼리를 사용하여 각 기법을 보여줍니다.:\n",
        "\"기후 변화가 환경에 미치는 영향은 무엇인가요?\"\n",
        "\n",
        "- **Query Rewriting** 이를 확장하여 온도 변화 및 생물 다양성과 같은 구체적인 측면을 포함합니다.\n",
        "- **Step-back Prompting** 이를 "기후 변화의 일반적인 영향은 무엇인가?"로 일반화합니다.\"\n",
        "- **Sub-query Decomposition** 이를 생물 다양성, 해양, 기상 패턴 및 육상 환경에 관한 질문으로 세분화합니다.\n",
        "\n",
        "## 결론\n",
        "\n",
        "이러한 질의 변환 기법은 RAG 시스템의 검색 기능을 향상시키는 강력한 방법을 제공합니다. 다양한 방식으로 질의를 재구성함으로써 검색된 정보의 관련성, 맥락 및 포괄성을 크게 개선할 수 있습니다. 이러한 방법은 과학 연구, 법률 분석 또는 포괄적인 사실 조사 작업과 같이 질의가 복잡하거나 다면적인 영역에서 특히 유용합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Package Installation and Imports\n",
        "\n",
        "The cell below installs all necessary packages required to run this notebook.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install required packages\n",
        "!pip install langchain langchain-openai python-dotenv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "#from langchain.prompts import PromptTemplate\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "\n",
        "import os\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "# Load environment variables from a .env file\n",
        "load_dotenv()\n",
        "\n",
        "# Set the OpenAI API key environment variable\n",
        "os.environ[\"OPENAI_API_KEY\"] = os.getenv('OPENAI_API_KEY')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1 - Query Rewriting: Reformulating queries to improve retrieval."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "re_write_llm = ChatOpenAI(temperature=0, model_name=\"gpt-4o\", max_tokens=4000)\n",
        "\n",
        "# Create a prompt template for query rewriting\n",
        "query_rewrite_template = \"\"\"You are an AI assistant tasked with reformulating user queries to improve retrieval in a RAG system. \n",
        "Given the original query, rewrite it to be more specific, detailed, and likely to retrieve relevant information.\n",
        "\n",
        "Original query: {original_query}\n",
        "\n",
        "Rewritten query:\"\"\"\n",
        "\n",
        "query_rewrite_prompt = PromptTemplate(\n",
        "    input_variables=[\"original_query\"],\n",
        "    template=query_rewrite_template\n",
        ")\n",
        "\n",
        "# Create an LLMChain for query rewriting\n",
        "query_rewriter = query_rewrite_prompt | re_write_llm\n",
        "\n",
        "def rewrite_query(original_query):\n",
        "    \"\"\"\n",
        "    Rewrite the original query to improve retrieval.\n",
        "    \n",
        "    Args:\n",
        "    original_query (str): The original user query\n",
        "    \n",
        "    Returns:\n",
        "    str: The rewritten query\n",
        "    \"\"\"\n",
        "    response = query_rewriter.invoke(original_query)\n",
        "    return response.content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Demonstrate on a use case"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original query: What are the impacts of climate change on the environment?\n",
            "\n",
            "Rewritten query: What are the specific effects of climate change on various ecosystems, including changes in temperature, precipitation patterns, sea levels, and biodiversity?\n"
          ]
        }
      ],
      "source": [
        "# example query over the understanding climate change dataset\n",
        "original_query = \"What are the impacts of climate change on the environment?\"\n",
        "rewritten_query = rewrite_query(original_query)\n",
        "print(\"Original query:\", original_query)\n",
        "print(\"\\nRewritten query:\", rewritten_query)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2 - Step-back Prompting: Generating broader queries for better context retrieval.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "step_back_llm = ChatOpenAI(temperature=0, model_name=\"gpt-4o\", max_tokens=4000)\n",
        "\n",
        "\n",
        "# Create a prompt template for step-back prompting\n",
        "step_back_template = \"\"\"You are an AI assistant tasked with generating broader, more general queries to improve context retrieval in a RAG system.\n",
        "Given the original query, generate a step-back query that is more general and can help retrieve relevant background information.\n",
        "\n",
        "Original query: {original_query}\n",
        "\n",
        "Step-back query:\"\"\"\n",
        "\n",
        "step_back_prompt = PromptTemplate(\n",
        "    input_variables=[\"original_query\"],\n",
        "    template=step_back_template\n",
        ")\n",
        "\n",
        "# Create an LLMChain for step-back prompting\n",
        "step_back_chain = step_back_prompt | step_back_llm\n",
        "\n",
        "def generate_step_back_query(original_query):\n",
        "    \"\"\"\n",
        "    Generate a step-back query to retrieve broader context.\n",
        "    \n",
        "    Args:\n",
        "    original_query (str): The original user query\n",
        "    \n",
        "    Returns:\n",
        "    str: The step-back query\n",
        "    \"\"\"\n",
        "    response = step_back_chain.invoke(original_query)\n",
        "    return response.content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Demonstrate on a use case"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original query: What are the impacts of climate change on the environment?\n",
            "\n",
            "Step-back query: What are the general effects of climate change?\n"
          ]
        }
      ],
      "source": [
        "# example query over the understanding climate change dataset\n",
        "original_query = \"What are the impacts of climate change on the environment?\"\n",
        "step_back_query = generate_step_back_query(original_query)\n",
        "print(\"Original query:\", original_query)\n",
        "print(\"\\nStep-back query:\", step_back_query)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3- Sub-query Decomposition: Breaking complex queries into simpler sub-queries."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "sub_query_llm = ChatOpenAI(temperature=0, model_name=\"gpt-4o\", max_tokens=4000)\n",
        "\n",
        "# Create a prompt template for sub-query decomposition\n",
        "subquery_decomposition_template = \"\"\"You are an AI assistant tasked with breaking down complex queries into simpler sub-queries for a RAG system.\n",
        "Given the original query, decompose it into 2-4 simpler sub-queries that, when answered together, would provide a comprehensive response to the original query.\n",
        "\n",
        "Original query: {original_query}\n",
        "\n",
        "example: What are the impacts of climate change on the environment?\n",
        "\n",
        "Sub-queries:\n",
        "1. What are the impacts of climate change on biodiversity?\n",
        "2. How does climate change affect the oceans?\n",
        "3. What are the effects of climate change on agriculture?\n",
        "4. What are the impacts of climate change on human health?\"\"\"\n",
        "\n",
        "\n",
        "subquery_decomposition_prompt = PromptTemplate(\n",
        "    input_variables=[\"original_query\"],\n",
        "    template=subquery_decomposition_template\n",
        ")\n",
        "\n",
        "# Create an LLMChain for sub-query decomposition\n",
        "subquery_decomposer_chain = subquery_decomposition_prompt | sub_query_llm\n",
        "\n",
        "def decompose_query(original_query: str):\n",
        "    \"\"\"\n",
        "    Decompose the original query into simpler sub-queries.\n",
        "    \n",
        "    Args:\n",
        "    original_query (str): The original complex query\n",
        "    \n",
        "    Returns:\n",
        "    List[str]: A list of simpler sub-queries\n",
        "    \"\"\"\n",
        "    response = subquery_decomposer_chain.invoke(original_query).content\n",
        "    sub_queries = [q.strip() for q in response.split('\\n') if q.strip() and not q.strip().startswith('Sub-queries:')]\n",
        "    return sub_queries"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Demonstrate on a use case"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Sub-queries:\n",
            "Original query: What are the impacts of climate change on the environment?\n",
            "1. How does climate change affect biodiversity and ecosystems?\n",
            "2. What are the impacts of climate change on oceanic conditions and marine life?\n",
            "3. How does climate change influence weather patterns and extreme weather events?\n",
            "4. What are the effects of climate change on terrestrial environments, such as forests and deserts?\n"
          ]
        }
      ],
      "source": [
        "# example query over the understanding climate change dataset\n",
        "original_query = \"What are the impacts of climate change on the environment?\"\n",
        "sub_queries = decompose_query(original_query)\n",
        "print(\"\\nSub-queries:\")\n",
        "for i, sub_query in enumerate(sub_queries, 1):\n",
        "    print(sub_query)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![](https://europe-west1-rag-techniques-views-tracker.cloudfunctions.net/rag-techniques-tracker?notebook=all-rag-techniques--query-transformations)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
